# Awesome Chinese LLM: A curated list of Chinese Large Language Model

# Datasets

* [NKCorpus](https://gitee.com/lidongwen1997/nkunlp-preprocessing) - 利用海量网络数据构建大型高质量中文数据集
* [BELLE](https://github.com/LianjiaTech/BELLE/tree/main/data/10M) - 10M中文数据集

# Pre-trained LLM

| Model | Size | Architecture | Repo/Chkpt | Paper | 
| ----- | ---- | ------------ | ----------- | ----- |
| 鹏程.盘古α | 13B | Decoder | [Github](https://github.com/huawei-noah/Pretrained-Language-Model) | [Paper](https://arxiv.org/pdf/2104.12369.pdf) |
| GLM | 130B | Decoder | [Github](https://github.com/THUDM/GLM-130B) | [Paper](https://arxiv.org/pdf/2210.02414.pdf) |
| MOSS | | | [Github](https://github.com/OpenLMLab/MOSS) |

# Instruction finetuned LLM
| Model | Size | Backbone | Repo/Chkpt | Paper | 
| ----- | ---- | ------------ | ----------- | ----- |
| Chinese-Vicuna | 7B | LlaMA | [Github](https://github.com/Facico/Chinese-Vicuna) | |
| BELLE | 7B, 13b | LlaMA | [Github](https://github.com/LianjiaTech/BELLE) |
| ChatGLM-6B| 6B | GLM | [Github](https://github.com/THUDM/ChatGLM-6B) |

