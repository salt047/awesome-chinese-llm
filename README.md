# Awesome Chinese LLM: A curated list of Chinese Large Language Model

# Datasets

* [BELLE](https://github.com/LianjiaTech/BELLE/tree/main/data/10M) - 10M中文数据集
* [Chinese book](https://github.com/JiangYanting/Chinese_book_dataset) - 中文图书数据集/数据挖掘/自然语言处理/中国图书分类法/图书情报学/数据挖掘/文本分类/
* [Chinese Scientific Literature Dataset](https://github.com/ydli-ai/CSL) - A Large-scale Chinese Scientific Literature Dataset 中文科学文献数据集
* [chinese-poetry](https://github.com/chinese-poetry/chinese-poetry) - 最全中华古诗词数据库, 唐宋两朝近一万四千古诗人, 接近5.5万首唐诗加26万宋诗. 两宋时期1564位词人，21050首词。
* [CLUECorpus2020](https://github.com/CLUEbenchmark/CLUECorpus2020/) - 通过对Common Crawl的中文部分进行语料清洗，最终得到100GB的高质量中文预训练语料
* [MNBVC(Massive Never-ending BT Vast Chinese corpus)超大规模中文语料集](https://github.com/esbatmop/MNBVC) - 对标chatGPT训练的40T数据。MNBVC数据集不但包括主流文化，也包括各个小众文化甚至火星文的数据。MNBVC数据集包括新闻、作文、小说、书籍、杂志、论文、台词、帖子、wiki、古诗、歌词、商品介绍、笑话、糗事、聊天记录等一切形式的纯文本中文数据。
* [MOSS](https://github.com/OpenLMLab/MOSS#%E6%95%B0%E6%8D%AE) - MOSS训练数据
* [News Commentary v13](https://github.com/dbiir/UER-py/wiki/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE) - News Commentary v13包括平行语料
* [NKCorpus](https://gitee.com/lidongwen1997/nkunlp-preprocessing) - 利用海量网络数据构建大型高质量中文数据集
* [pretrain_zh](https://github.com/TigerResearch/TigerBot#%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86) - 中文开源预训练集 - 55G，包含中文书籍、中文互联网、中文百科
* [THUCNews](http://thuctc.thunlp.org/) - 根据新浪新闻RSS订阅频道2005~2011年间的历史数据筛选过滤生成，包含74万篇新闻文档，划分出 14 个候选分类。
* [WuDaoCorpora Text文本预训练数据集](https://data.baai.ac.cn/details/WuDaoCorporaText) - 北京智源人工智能研究院（智源研究院）构建的大规模、高质量数据集
* [千言](https://www.luge.ai/) - 百度联合中国计算机学会自然语言处理专委会、中国中文信息学会评测工作委员会共同发起的,由来自国内多家高校和企业的数据资源研发者共同建设的中文开源数据集。
* [天池](https://tianchi.aliyun.com/dataset/) - 天池数据集是阿里集团对外开放的科研数据平台,由阿里巴巴集团业务团队和外部研究机构联合提供,覆盖了电商、娱乐、物流、医疗健康、交通、工业、自然科学、能源等十多个行业。
* [清华大学NLP实验室开放数据集](http://thuocl.thunlp.org/) - 清华大学自然语言处理与社会人文计算实验室维护的中文自然语言处理共享平台，提供了大量的中文文本数据集，包括新闻、论坛、微博、问答等。
* [中文医疗问答数据集](https://github.com/Toyhom/Chinese-medical-dialogue-data)
* [[COLING 2022] CSL](https://github.com/ydli-ai/CSL): A Large-scale Chinese Scientific Literature Dataset 中文科学文献数据集
* [中文公开聊天语料库](https://github.com/codemayq/chinese-chatbot-corpus)


# Pre-trained LLM

| Model | Size | Architecture | Repo/Chkpt | Paper | 
| ----- | ---- | ------------ | ----------- | ----- |
| 鹏程.盘古α | 13B | Decoder | [Github](https://github.com/huawei-noah/Pretrained-Language-Model) | [Paper](https://arxiv.org/pdf/2104.12369.pdf) |
| GLM | 130B | Decoder | [Github](https://github.com/THUDM/GLM-130B) | [Paper](https://arxiv.org/pdf/2210.02414.pdf) |
| MOSS | | | [Github](https://github.com/OpenLMLab/MOSS) |
| TigerBot: A multi-language multi-task LLM| TigerBot-7B, TigerBot-7B-base，TigerBot-180B| | [Github](https://github.com/TigerResearch/TigerBot) |
| baichuan-7B: A large-scale 7B pretraining language model developed by BaiChuan-Inc. | 7B | | [Github](https://github.com/baichuan-inc/baichuan-7B) |


